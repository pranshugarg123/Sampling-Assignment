{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7c7092e-df2a-4efa-8bd9-b08053d15181",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_4/6fj77k5s69x3cmq2yz3rf0pc0000gn/T/ipykernel_30612/499024527.py:70: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results = pd.concat([results, new_row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Model   Sampling  Accuracy\n",
      "0     M1  Sampling1  0.896552\n",
      "1     M2  Sampling1  0.987069\n",
      "2     M3  Sampling1  0.948276\n",
      "3     M4  Sampling1  0.922414\n",
      "4     M5  Sampling1  0.974138\n",
      "5     M1  Sampling2  0.478448\n",
      "6     M2  Sampling2  0.676724\n",
      "7     M3  Sampling2  0.560345\n",
      "8     M4  Sampling2  0.409483\n",
      "9     M5  Sampling2  0.784483\n",
      "10    M1  Sampling3  0.896552\n",
      "11    M2  Sampling3  0.987069\n",
      "12    M3  Sampling3  0.943966\n",
      "13    M4  Sampling3  0.943966\n",
      "14    M5  Sampling3  0.982759\n",
      "15    M1  Sampling4  0.331897\n",
      "16    M2  Sampling4  0.211207\n",
      "17    M3  Sampling4  0.250000\n",
      "18    M4  Sampling4  0.758621\n",
      "19    M5  Sampling4  0.443966\n",
      "20    M1  Sampling5  0.883621\n",
      "21    M2  Sampling5  0.987069\n",
      "22    M3  Sampling5  0.939655\n",
      "23    M4  Sampling5  0.900862\n",
      "24    M5  Sampling5  0.969828\n",
      "\n",
      "Best Sampling Technique for Each Model:\n",
      "   Model   Sampling  Accuracy\n",
      "0     M1  Sampling1  0.896552\n",
      "1     M2  Sampling1  0.987069\n",
      "2     M3  Sampling1  0.948276\n",
      "13    M4  Sampling3  0.943966\n",
      "14    M5  Sampling3  0.982759\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import urllib.request\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('creditcard_data.csv')\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(columns=['Class'])\n",
    "y = df['Class']\n",
    "\n",
    "# Scale data (optional, but can help with convergence)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define sampling techniques\n",
    "samplers = {\n",
    "    'Sampling1': SMOTE(),\n",
    "    'Sampling2': RandomUnderSampler(),\n",
    "    'Sampling3': RandomOverSampler(),\n",
    "    'Sampling4': NearMiss(),\n",
    "    'Sampling5': SMOTEENN()\n",
    "}\n",
    "\n",
    "# Define machine learning models\n",
    "models = {\n",
    "    'M1': LogisticRegression(max_iter=500),\n",
    "    'M2': RandomForestClassifier(),\n",
    "    'M3': SVC(),\n",
    "    'M4': KNeighborsClassifier(),\n",
    "    'M5': GradientBoostingClassifier()\n",
    "}\n",
    "\n",
    "# Initialize an empty DataFrame for results\n",
    "results = pd.DataFrame(columns=[\"Model\", \"Sampling\", \"Accuracy\"])\n",
    "\n",
    "# Loop through sampling techniques and models\n",
    "for sampling_name, sampler in samplers.items():\n",
    "    # Apply the sampling technique on training data\n",
    "    X_sampled, y_sampled = sampler.fit_resample(X_train, y_train)\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        # Train the model\n",
    "        model.fit(X_sampled, y_sampled)\n",
    "        \n",
    "        # Predict on test data\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        # Append results\n",
    "        new_row = pd.DataFrame([{\"Model\": model_name, \"Sampling\": sampling_name, \"Accuracy\": acc}])\n",
    "        results = pd.concat([results, new_row], ignore_index=True)\n",
    "\n",
    "# Display results\n",
    "print(results)\n",
    "\n",
    "# Determine which sampling technique gives the highest accuracy for each model\n",
    "best_sampling_technique = results.loc[results.groupby(\"Model\")[\"Accuracy\"].idxmax()]\n",
    "\n",
    "# Display best sampling techniques for each model\n",
    "print(\"\\nBest Sampling Technique for Each Model:\")\n",
    "print(best_sampling_technique)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca6a69a-2c52-47c1-8426-79693dae177e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
